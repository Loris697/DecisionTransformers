{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee721db8-8e73-4159-b33a-45a42771bb4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-29 01:13:43.759890: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv, VecVideoRecorder\n",
    "import gymnasium as gym\n",
    "import random\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import Callable\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from Models.DecisionTransformer import DecisionTransformers\n",
    "\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a73163c-a365-4ff3-b5e4-12cb0e85db05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_modified_file(directory):\n",
    "    # Ensure the directory exists\n",
    "    if not os.path.exists(directory):\n",
    "        return None\n",
    "\n",
    "    # Initialize variables to track the last modified file and its time\n",
    "    latest_file = None\n",
    "    latest_mod_time = 0\n",
    "\n",
    "    # Loop through all files in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        # Get the full path of the file\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        \n",
    "        # Check if it's a file and not a directory\n",
    "        if os.path.isfile(filepath):\n",
    "            # Get the modification time of the file\n",
    "            mod_time = os.path.getmtime(filepath)\n",
    "            \n",
    "            # Update the latest file if this file is more recently modified\n",
    "            if mod_time > latest_mod_time:\n",
    "                latest_mod_time = mod_time\n",
    "                latest_file = filename\n",
    "\n",
    "    return latest_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91467aba-8cb6-411c-8de6-9217d068bd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_id = 'CarRacing-v2'\n",
    "render_mode = \"human\"\n",
    "\n",
    "env = DummyVecEnv([lambda: gym.make(env_id, render_mode=render_mode)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e23cbc05-f6ff-4cf4-acdd-11fa08a9aca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last modified file: epoch=98-train_loss=0.06-val_loss=0.07.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "directory_path = 'checkpoints/'\n",
    "model_checkpoints = get_last_modified_file(directory_path)\n",
    "print(\"Last modified file:\", model_checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "528b3de0-e90e-4bab-9612-a0d2c5e1d688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of learnable parameters for the CNN: 2728064\n",
      "Number of learnable parameters for the entire architecture: 10679171\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTransformers(\n",
       "  (embedding_reward): Linear(in_features=1, out_features=128, bias=True)\n",
       "  (embedding_action): Linear(in_features=3, out_features=128, bias=True)\n",
       "  (embedding_observation): CustomResNet(\n",
       "    (first_cnn_layer): Sequential(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (1): LayerNorm((32, 94, 94), eps=1e-05, elementwise_affine=True)\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): Dropout2d(p=0.2, inplace=False)\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (second_cnn_layer): Sequential(\n",
       "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (1): LayerNorm((32, 45, 45), eps=1e-05, elementwise_affine=True)\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): Dropout2d(p=0.2, inplace=False)\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (cnn_layers): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (1): LayerNorm((32, 22, 22), eps=1e-05, elementwise_affine=True)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): Dropout2d(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (linear): Sequential(\n",
       "      (0): Linear(in_features=15488, out_features=128, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "    )\n",
       "  )\n",
       "  (transformer): TransformerArchitecture(\n",
       "    (activation): GELU(approximate='none')\n",
       "    (positional_embedding): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (attentions): ModuleList(\n",
       "      (0-23): 24 x MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (linear1): ModuleList(\n",
       "      (0-23): 24 x Linear(in_features=128, out_features=1024, bias=True)\n",
       "    )\n",
       "    (linear2): ModuleList(\n",
       "      (0-23): 24 x Linear(in_features=1024, out_features=128, bias=True)\n",
       "    )\n",
       "    (layer_norms1): ModuleList(\n",
       "      (0-23): 24 x LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (layer_norms2): ModuleList(\n",
       "      (0-23): 24 x LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (fc1): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (1): GELU(approximate='none')\n",
       "  )\n",
       "  (output): Linear(in_features=256, out_features=3, bias=True)\n",
       "  (huber_loss): SmoothL1Loss()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DecisionTransformers.load_from_checkpoint(directory_path + model_checkpoints, d_model = 128, action_space_dim = env.action_space.shape[0], \n",
    "                             observation_space = env.observation_space, max_seq_len = 64)\n",
    "\n",
    "# disable randomness, dropout, etc...\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a570b3cb-bfbf-4a2c-aa27-7614249dc630",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkAction(action):\n",
    "    #checking steering\n",
    "    if action[0] > 1:\n",
    "        print(\"Invalid steering. \", action[0])\n",
    "        action[0] = 1\n",
    "    elif action[0] < -1:\n",
    "        print(\"Invalid steering. \", action[0])\n",
    "        action[0] = 1\n",
    "    #checking gas\n",
    "    if action[1] > 1:\n",
    "        print(\"Invalid gas. \", action[1])\n",
    "        action[1] = 1\n",
    "    elif action[1] < 0:\n",
    "        print(\"Invalid gas. \", action[1])\n",
    "        action[1] = 0\n",
    "    #checking brake\n",
    "    if action[2] > 1:\n",
    "        print(\"Invalid brake. \", action[2])\n",
    "        action[2] = 1\n",
    "    elif action[2] < 0:\n",
    "        print(\"Invalid brake. \", action[2])\n",
    "        action[2] = 0\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb9a2549-7ad4-4055-8fdf-7ef8e6f0659e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTester:\n",
    "    def __init__(self, \n",
    "                 env_name: str,\n",
    "                 model: nn.Module,\n",
    "                 device: str = \"cuda\",\n",
    "                 seq_len: int = 32,\n",
    "                 render_mode: str = \"human\",\n",
    "                 actionCheck: Callable = None,\n",
    "                 max_reward: float = 800.,\n",
    "                ):\n",
    "        \"\"\"Initialize the tester with an environment and a model.\"\"\"\n",
    "        self.env = DummyVecEnv([lambda: gym.make(env_name, render_mode=render_mode)])\n",
    "        self.model = model.to(device=device)\n",
    "        self.device = device\n",
    "        self.seq_len = seq_len\n",
    "        self.actionCheck = actionCheck\n",
    "        self.max_reward = max_reward\n",
    "\n",
    "        #defining the inputs\n",
    "        self.rewards = torch.zeros(1, seq_len, 1)\n",
    "        self.observations = torch.zeros(1, seq_len, env.observation_space.shape[2], env.observation_space.shape[0], env.observation_space.shape[1])\n",
    "        self.actions = torch.zeros(1, seq_len, env.action_space.shape[0])\n",
    "    \n",
    "    def run_episode(self, \n",
    "                    render: bool = False,\n",
    "                    starting_rewards: float = 1.,\n",
    "                    starting_action: gym.spaces.Space = None\n",
    "                   ):\n",
    "        \"\"\"Run one episode to test the model.\"\"\"\n",
    "        state = self.env.reset()\n",
    "        done = False\n",
    "        total_reward = 0\n",
    "        step = 0 \n",
    "        if starting_action is None:\n",
    "            starting_action = self.env.action_space.sample()\n",
    "\n",
    "        #init the sequence\n",
    "        self.reset_sequence()\n",
    "\n",
    "        self.rewards[0][step] = torch.tensor(starting_rewards)\n",
    "        self.actions[0][step] = torch.tensor(starting_action)\n",
    "        self.observations[0][step] = torch.tensor(np.array(state)/ 255. ).squeeze(0).permute(2, 0, 1)\n",
    "\n",
    "        while not done:\n",
    "            if render:\n",
    "                self.env.render()\n",
    "\n",
    "            action = self.model({\n",
    "                \"rewards\" : self.rewards.to(device=self.device, dtype=torch.float32),\n",
    "                \"observations\" : self.observations.to(device=self.device, dtype=torch.float32),\n",
    "                \"actions\" : self.actions.to(device=self.device, dtype=torch.float32),\n",
    "            })\n",
    "            next_action = np.array(action[0][step].cpu().detach())\n",
    "            if self.actionCheck is not None:\n",
    "                next_action = self.actionCheck(next_action)\n",
    "            \n",
    "            state, reward, done, info = self.env.step([next_action])\n",
    "            \n",
    "            next_reward = self.rewards[0][0].cpu().item() * self.max_reward - reward\n",
    "\n",
    "            # updating the sequence of rewards, observations, actions\n",
    "            if step < self.seq_len - 1:\n",
    "                step += 1\n",
    "                self.rewards[0][step] = torch.tensor(next_reward/self.max_reward)\n",
    "                self.actions[0][step] = torch.tensor(next_action)\n",
    "                self.observations[0][step] = torch.tensor(np.array(state)/ 255. ).squeeze(0).permute(2, 0, 1)\n",
    "            else:\n",
    "                self.rewards = torch.cat([self.rewards[:,1:], torch.tensor(next_reward/self.max_reward).reshape(1, 1, -1)], dim=1)\n",
    "                self.observations = torch.cat([self.observations[:,1:], torch.tensor(state/255.).permute(0, 3, 1, 2).unsqueeze(0)], dim=1) \n",
    "                self.actions = torch.cat([self.actions[:,1:], torch.tensor(next_action).reshape(1, 1, -1)], dim=1) \n",
    "            \n",
    "            total_reward += reward\n",
    "\n",
    "        return total_reward\n",
    "    \n",
    "    def test_model(self, episodes=100, render=False):\n",
    "        \"\"\"Test the model over a number of episodes and average the rewards.\"\"\"\n",
    "        total_rewards = [self.run_episode(render=render) for _ in range(episodes)]\n",
    "        average_reward = sum(total_rewards) / episodes\n",
    "        return average_reward\n",
    "\n",
    "    def close_env(self):\n",
    "        \"\"\"Close the Gym environment.\"\"\"\n",
    "        self.env.close()\n",
    "\n",
    "    def reset_sequence(self):\n",
    "        \"\"\"Deleting the sequences.\"\"\"\n",
    "        self.rewards = torch.zeros(1, self.seq_len, 1)\n",
    "        self.observations = torch.zeros(1, self.seq_len, env.observation_space.shape[2], env.observation_space.shape[0], env.observation_space.shape[1])\n",
    "        self.actions = torch.zeros(1, self.seq_len, env.action_space.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6db80be9-22bb-47c9-8615-9138df603b77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid brake.  -9.012967e-05\n",
      "Invalid brake.  -0.008850243\n",
      "Invalid brake.  -0.0031641573\n",
      "Invalid brake.  -0.0016443059\n",
      "Invalid brake.  -0.0040624924\n",
      "Invalid brake.  -0.0017506182\n",
      "Invalid brake.  -0.004779052\n",
      "Invalid brake.  -0.0048908517\n",
      "Invalid brake.  -0.015899658\n",
      "Invalid brake.  -0.028963096\n",
      "Invalid brake.  -0.0047607757\n",
      "Invalid brake.  -0.0009059943\n",
      "Invalid brake.  -0.0038973764\n",
      "Invalid brake.  -0.0027975924\n",
      "Invalid brake.  -0.0025800914\n",
      "Invalid brake.  -0.0006334521\n",
      "Invalid brake.  -0.004620502\n",
      "Invalid brake.  -0.013505805\n",
      "Invalid brake.  -0.009927407\n",
      "Invalid brake.  -0.001940459\n",
      "Invalid brake.  -0.005467184\n",
      "Invalid brake.  -0.006068997\n",
      "Invalid brake.  -0.0007993281\n",
      "Invalid brake.  -0.010205474\n",
      "Invalid brake.  -0.008546583\n",
      "Invalid brake.  -0.002854988\n",
      "Invalid brake.  -0.0021985024\n",
      "Invalid brake.  -0.0024382435\n",
      "Invalid brake.  -0.0024226606\n",
      "Invalid brake.  -0.007389471\n",
      "Invalid brake.  -0.015647437\n",
      "Invalid brake.  -0.022207424\n",
      "Invalid brake.  -0.00816071\n",
      "Invalid brake.  -0.011428585\n",
      "Invalid brake.  -0.010422483\n",
      "Invalid brake.  -0.005391922\n",
      "Invalid brake.  -0.010485757\n",
      "Invalid brake.  -0.0012591705\n",
      "Invalid brake.  -0.0012502447\n",
      "Invalid brake.  -2.9988587e-05\n",
      "Invalid brake.  -0.0004557483\n",
      "Invalid brake.  -0.0034624413\n",
      "Invalid brake.  -0.017929353\n",
      "Invalid brake.  -0.0037001334\n",
      "Invalid brake.  -0.0037987158\n",
      "Invalid brake.  -0.0069740564\n",
      "Invalid brake.  -0.014071804\n",
      "Invalid brake.  -0.016736582\n",
      "Invalid brake.  -0.0021955073\n",
      "Invalid brake.  -0.004356578\n",
      "Invalid brake.  -0.001087945\n",
      "Invalid brake.  -0.0033653304\n",
      "Invalid brake.  -0.007476166\n",
      "Invalid brake.  -0.022919767\n",
      "Invalid brake.  -0.0091471225\n",
      "Invalid brake.  -0.0009334907\n",
      "Invalid brake.  -0.02230271\n",
      "Invalid brake.  -0.027781524\n",
      "Invalid brake.  -0.0057924055\n",
      "Invalid brake.  -0.012126651\n",
      "Invalid brake.  -0.00960926\n",
      "Invalid brake.  -0.008313023\n",
      "Invalid brake.  -0.0020813048\n",
      "Invalid brake.  -0.009026773\n",
      "Invalid brake.  -0.010910645\n",
      "Invalid brake.  -0.0058918223\n",
      "Invalid brake.  -0.004151523\n",
      "Invalid brake.  -0.004996948\n",
      "Invalid brake.  -0.0014377423\n",
      "Invalid brake.  -0.011252373\n",
      "Invalid brake.  -0.021395855\n",
      "Invalid brake.  -0.016677216\n",
      "Invalid brake.  -0.015761465\n",
      "Invalid brake.  -0.011808205\n",
      "Invalid brake.  -0.0038518906\n",
      "Invalid brake.  -0.007507134\n",
      "Invalid brake.  -0.01867966\n",
      "Invalid brake.  -0.026192874\n",
      "Invalid brake.  -0.019595794\n",
      "Invalid brake.  -0.023256235\n",
      "Invalid brake.  -0.042735487\n",
      "Invalid brake.  -0.01820806\n",
      "Invalid brake.  -0.015145011\n",
      "Invalid brake.  -0.0027823523\n",
      "Invalid brake.  -0.013036616\n",
      "Invalid brake.  -0.0023930743\n",
      "Invalid brake.  -0.0017131567\n",
      "Invalid brake.  -0.018895544\n",
      "Invalid brake.  -0.013933204\n",
      "Invalid brake.  -0.009444784\n",
      "Invalid brake.  -0.017848335\n",
      "Invalid brake.  -0.0049681105\n",
      "Invalid brake.  -0.01652531\n",
      "Invalid brake.  -0.0022126585\n",
      "Invalid brake.  -0.000992924\n",
      "Invalid brake.  -0.00035765022\n",
      "Invalid brake.  -0.0013859197\n",
      "Invalid brake.  -0.011554435\n",
      "Invalid brake.  -0.0075212345\n",
      "Invalid brake.  -0.008346561\n",
      "Invalid brake.  -0.012045376\n",
      "Invalid brake.  -0.0064218864\n",
      "Invalid brake.  -0.003567949\n",
      "Invalid brake.  -0.000518173\n",
      "Invalid brake.  -0.0058902577\n",
      "Invalid brake.  -0.015252255\n",
      "Invalid brake.  -0.017334059\n",
      "Invalid brake.  -0.0023363903\n",
      "Invalid brake.  -0.016293284\n",
      "Invalid brake.  -0.010994531\n",
      "Invalid brake.  -0.008317657\n",
      "Invalid brake.  -0.008430235\n",
      "Invalid brake.  -0.03181334\n",
      "Invalid steering.  -1.0467327\n",
      "Invalid brake.  -0.009545855\n",
      "Invalid brake.  -0.007412944\n",
      "Invalid brake.  -0.009171382\n",
      "Invalid brake.  -0.016384188\n",
      "Invalid brake.  -0.01447615\n",
      "Invalid brake.  -0.0068721995\n",
      "Invalid brake.  -0.005562324\n",
      "Invalid brake.  -0.0040370002\n",
      "Invalid brake.  -0.0026870668\n",
      "Invalid brake.  -0.0022495221\n",
      "Invalid brake.  -0.0019823313\n",
      "Invalid brake.  -0.0025092661\n",
      "Invalid brake.  -0.0005382523\n",
      "Invalid brake.  -0.011735477\n",
      "Invalid brake.  -0.01138752\n",
      "Invalid brake.  -0.0012548566\n",
      "Invalid brake.  -0.00059328973\n",
      "Invalid brake.  -0.016205631\n",
      "Invalid brake.  -0.004454352\n",
      "Invalid brake.  -0.0030124001\n",
      "Invalid brake.  -0.0005556047\n",
      "Invalid brake.  -0.0015621334\n",
      "Invalid brake.  -0.01970464\n",
      "Invalid brake.  -0.01046288\n",
      "Invalid brake.  -0.014315717\n",
      "Invalid brake.  -0.004583694\n",
      "Invalid brake.  -0.016155262\n",
      "Invalid brake.  -0.010070056\n",
      "Invalid brake.  -0.013612229\n",
      "Invalid brake.  -0.021191187\n",
      "Invalid brake.  -0.0047015324\n",
      "Invalid brake.  -0.0043317676\n",
      "Invalid brake.  -0.014380153\n",
      "Invalid brake.  -0.010927215\n",
      "Invalid brake.  -0.02144685\n",
      "Invalid brake.  -0.009655394\n",
      "Invalid brake.  -0.0090851635\n",
      "Invalid brake.  -0.00942\n",
      "Invalid brake.  -0.01545424\n",
      "Invalid brake.  -0.0069598854\n",
      "Invalid brake.  -0.0018913448\n",
      "Invalid brake.  -0.0073582605\n",
      "Invalid brake.  -0.009534106\n",
      "Invalid brake.  -0.00462294\n",
      "Invalid brake.  -0.017402947\n",
      "Invalid brake.  -0.015819564\n",
      "Invalid brake.  -0.010635264\n",
      "Invalid brake.  -0.0023605898\n",
      "Invalid brake.  -0.011893278\n",
      "Invalid brake.  -0.018162884\n",
      "Invalid brake.  -0.009951524\n",
      "Invalid brake.  -0.0028911382\n",
      "Invalid brake.  -0.0007055402\n",
      "Invalid brake.  -0.0006875843\n",
      "Invalid brake.  -0.003199689\n",
      "Invalid brake.  -0.0012530163\n",
      "Invalid brake.  -0.0069013536\n",
      "Invalid brake.  -0.021405384\n",
      "Invalid brake.  -0.01877597\n",
      "Invalid brake.  -0.015100524\n",
      "Invalid brake.  -0.012132451\n",
      "Invalid brake.  -0.014862932\n",
      "Invalid brake.  -0.026747197\n",
      "Invalid brake.  -0.024278529\n",
      "Invalid brake.  -0.0014864169\n",
      "Invalid brake.  -0.0018099099\n",
      "Invalid brake.  -0.008144546\n",
      "Invalid brake.  -0.00435026\n",
      "Invalid brake.  -0.014149297\n",
      "Invalid brake.  -0.009039991\n",
      "Invalid brake.  -0.014613483\n",
      "Invalid brake.  -0.0011020452\n",
      "Invalid brake.  -0.0030002967\n",
      "Invalid brake.  -0.0030522943\n",
      "Invalid brake.  -0.0054824688\n",
      "Invalid brake.  -0.014040582\n",
      "Invalid brake.  -0.00010129064\n",
      "Invalid brake.  -0.0084778555\n",
      "Invalid brake.  -0.004905492\n",
      "Invalid brake.  -0.0039251745\n",
      "Invalid brake.  -0.0015683025\n",
      "Invalid brake.  -0.02000671\n",
      "Invalid brake.  -0.009168796\n",
      "Invalid brake.  -0.008504681\n",
      "Invalid brake.  -0.017018482\n",
      "Invalid brake.  -0.014922157\n",
      "Invalid brake.  -0.0022984073\n",
      "Invalid brake.  -0.007214926\n",
      "Invalid brake.  -0.02807919\n",
      "Invalid brake.  -0.03774385\n",
      "Invalid brake.  -0.0013311505\n",
      "Invalid brake.  -0.020914711\n",
      "Invalid brake.  -0.008033611\n",
      "Invalid brake.  -0.0020277053\n",
      "Invalid brake.  -0.0005657673\n",
      "Invalid brake.  -0.00038883463\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m model_tester \u001b[38;5;241m=\u001b[39m ModelTester(model \u001b[38;5;241m=\u001b[39m model, \n\u001b[1;32m      2\u001b[0m                            env_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCarRacing-v2\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      3\u001b[0m                            actionCheck \u001b[38;5;241m=\u001b[39m checkAction,\n\u001b[1;32m      4\u001b[0m                            seq_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m,\n\u001b[1;32m      5\u001b[0m                           )\n\u001b[0;32m----> 6\u001b[0m \u001b[43mmodel_tester\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepisodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 78\u001b[0m, in \u001b[0;36mModelTester.test_model\u001b[0;34m(self, episodes, render)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, episodes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, render\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     77\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Test the model over a number of episodes and average the rewards.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m     total_rewards \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_episode(render\u001b[38;5;241m=\u001b[39mrender) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(episodes)]\n\u001b[1;32m     79\u001b[0m     average_reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(total_rewards) \u001b[38;5;241m/\u001b[39m episodes\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m average_reward\n",
      "Cell \u001b[0;32mIn[9], line 78\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, episodes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, render\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     77\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Test the model over a number of episodes and average the rewards.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m     total_rewards \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_episode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(episodes)]\n\u001b[1;32m     79\u001b[0m     average_reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(total_rewards) \u001b[38;5;241m/\u001b[39m episodes\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m average_reward\n",
      "Cell \u001b[0;32mIn[9], line 57\u001b[0m, in \u001b[0;36mModelTester.run_episode\u001b[0;34m(self, render, starting_rewards, starting_action)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactionCheck \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     55\u001b[0m     next_action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactionCheck(next_action)\n\u001b[0;32m---> 57\u001b[0m state, reward, done, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnext_action\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m next_reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrewards[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_reward \u001b[38;5;241m-\u001b[39m reward\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# updating the sequence of rewards, observations, actions\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:206\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;124;03mStep the environments with the given action\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \n\u001b[1;32m    202\u001b[0m \u001b[38;5;124;03m:param actions: the action\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m:return: observation, reward, done, information\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_async(actions)\n\u001b[0;32m--> 206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:58\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VecEnvStepReturn:\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;66;03m# Avoid circular imports\u001b[39;00m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m env_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs):\n\u001b[0;32m---> 58\u001b[0m         obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_rews[env_idx], terminated, truncated, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos[env_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvs\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactions\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;66;03m# convert to SB3 VecEnv api\u001b[39;00m\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones[env_idx] \u001b[38;5;241m=\u001b[39m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gymnasium/wrappers/time_limit.py:57\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[1;32m     47\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m \n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m     observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_episode_steps:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gymnasium/wrappers/order_enforcing.py:56\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gymnasium/wrappers/env_checker.py:51\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_step_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, action)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gymnasium/envs/box2d/car_racing.py:553\u001b[0m, in \u001b[0;36mCarRacing.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworld\u001b[38;5;241m.\u001b[39mStep(\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m FPS, \u001b[38;5;241m6\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m30\u001b[39m)\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m FPS\n\u001b[0;32m--> 553\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_render\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstate_pixels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    555\u001b[0m step_reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    556\u001b[0m terminated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gymnasium/envs/box2d/car_racing.py:605\u001b[0m, in \u001b[0;36mCarRacing._render\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[1;32m    603\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m  \u001b[38;5;66;03m# reset() not called yet\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msurf \u001b[38;5;241m=\u001b[39m \u001b[43mpygame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSurface\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mWINDOW_W\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mWINDOW_H\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcar \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;66;03m# computing transformations\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_tester = ModelTester(model = model, \n",
    "                           env_name = 'CarRacing-v2',\n",
    "                           actionCheck = checkAction,\n",
    "                           seq_len = 64,\n",
    "                          )\n",
    "model_tester.test_model(episodes=1, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5518af57-5f21-4192-9117-3a93d5eab819",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
